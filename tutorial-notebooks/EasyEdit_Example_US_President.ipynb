{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyEdit Example with the **US President**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Tutorial author: Kewei Xu（<kewe1x@163.con>）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently the U.S. election has concluded, and `Donald Trump` has been elected President. <br>\n",
    "We tested knowledge editing in this scenario:\n",
    "- `Biden → Trump` <br> \n",
    "- `Biden → Trump → Biden` (simulating the interesting shift of Trump → Biden → Trump).<br>\n",
    "\n",
    "In this tutorial, we use `Wise`、`AlphaEdit`、`LoRA`、`Prompt` to edit `Llama3-8B`.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### WISE\n",
    "Paper: [WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models?](http://arxiv.org/pdf/2405.14768)\n",
    "    \n",
    "**WISE**, is an approach for lifelong model editing of Large Language Models (LLMs). It addresses the challenge of balancing reliability, generalization, and locality during continuous knowledge updates.\n",
    "It provides an effective solution for continuous learning and knowledge updating in large language models through its innovative memory management and editing strategies.\n",
    "\n",
    "### AlphaEdit\n",
    "Paper: [AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models](https://arxiv.org/pdf/2410.02355)\n",
    "\n",
    "**AlphaEdit** minimizes disruption to the preserved knowledge by projecting parameter perturbations onto the null space of its key matrices. It then removes the output error related to it from the current objective, allowing the model to focus solely on knowledge update without trade-off. By leveraging the mathematical properties of matrix projection and null space, AlphaEdit ensures that the distribution of hidden representations within LLMs remains invariant after edits. This invariance allows post-edited LLMs to effectively handle both knowledge update and preservation simultaneously.\n",
    "\n",
    "### AdaLoRA\n",
    "Paper: [AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.10512)\n",
    "\n",
    "**AdaLoRA** introduces a method that efficiently fine-tunes large pre-trained language models by adaptively allocating update budgets based on parameter importance. Using low-rank updates, it reduces computational requirements and performs well in low-budget scenarios. The code is available on GitHub\n",
    "\n",
    "### Prompt\n",
    "Guide the model to answer through prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested the following indicators:\n",
    "- `Reliability`: the success rate of editing with a given editing descriptor<br>\n",
    "**Question**: *Who is the current President of the United States?*\n",
    "\n",
    "- `Generalization`: the success rate of editing within the editing scope<br>\n",
    "**Question**: *Who is the head of state in the United States right now?*\n",
    "\n",
    "- `Locality`: whether the model's output changes after editing for unrelated inputs<br>\n",
    "**Question**: *Where is the capital of the United States?*\n",
    "\n",
    "- `Portability`: the success rate of editing for reasoning/application(one hop, synonym, logical generalization)<br>\n",
    "**Question**: *Where is the current U.S. President born?*\n",
    "\n",
    "\n",
    "The editing results are shown in the table below, with **highlighted** areas indicating that the output **does not match the answer**.<br>\n",
    "From the table, it can be seen that:<br>\n",
    "**_Prompt_** can complete the task well.<br>\n",
    "**_WISE_** encountered Portability issues during the first editing.<br>\n",
    "**_LoRA_** is competent for the first editing, but there are exceptions for the second editing in Locality and Portability.<br>\n",
    "**_AlphaEdit_** has problems in both cases for Locality and Portability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><b>Reliability</b></td>\n",
    "        <td><b>Generalization</b></td>\n",
    "        <td><b>Locality</b></td>\n",
    "        <td><b>Portability</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Questions</b></td>\n",
    "        <td>Who is the current President of the United States?</td>\n",
    "        <td>Who is the head of state in the United States right now?</td>\n",
    "        <td>Where is the capital of the United States?</td>\n",
    "        <td>Where is the current U.S. President born? </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=5 align=\"center\"><b>First Edit:  Joe Biden ——&gt; Donald Trump</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Answer</b></td>\n",
    "        <td><b>Donald Trump</b></td>\n",
    "        <td><b>Donald Trump</b></td>\n",
    "        <td><b>Washington, D.C.</b></td>\n",
    "        <td><b>Queens, New York </b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>WISE</b></td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Washington, D.C</td>\n",
    "        <td>Queens, New York </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>AlphaEdit</b></td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Washington, D.C</td>\n",
    "        <td><mark>Donald Trump </mark></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>LoRA</b></td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Washington, D.C</td>\n",
    "        <td>Queens, New York </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Prompt</b></td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Donald Trump</td>\n",
    "        <td>Washington, D.C.</td>\n",
    "        <td>Queens, New York </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=5 align=\"center\"><b>Second Edit:   Joe Biden ——&gt; Donald Trump ——&gt; Joe Biden</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Answer</b></td>\n",
    "        <td><b>Joe Biden</b></td>\n",
    "        <td><b>Joe Biden</b></td>\n",
    "        <td><b>Washington, D.C.</b></td>\n",
    "        <td><b>Scranton, Pennsylvania </b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>WISE</b></td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Washington, D.C</td>\n",
    "        <td>Scranton, Pennsylvania </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>AlphaEdit</b></td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td><mark>Joe Biden</mark></td>\n",
    "        <td><mark>Joe Biden </mark></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>LoRA</b></td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td><mark>Joe Biden</mark></td>\n",
    "        <td><mark>Joe Biden </mark></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Prompt</b></td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Joe Biden</td>\n",
    "        <td>Washington, D.C</td>\n",
    "        <td>Scranton, Pennsylvania </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the current path is `EasyEdit/tutorial-notebooks`, run the following command to navigate to the `EasyEdit/` path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/8t/xkw/EasyEdit\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the evaluation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from easyeditor import BaseEditor\n",
    "Evaluation_prompts = [ \"Who is the current President of the United States?\" ,\n",
    "            'Who is the head of state in the United States right now?',\n",
    "            \"Where is the capital of the United States?\" ,\n",
    "            'Where is the current U.S. President born ?']\n",
    "Evaluation_metrics = [\"Reliability\",\"Generalization\", \"Locality\", \"Portability\"]\n",
    "\n",
    "def evaluate_chat_template(model, Evaluation_prompts,Evaluation_metrics, device=1):\n",
    "    device = f\"cuda:{device}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained('./hugging_cache/llama-3-8b-instruct')\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.padding_side='left'\n",
    "\n",
    "    for i in range(len(Evaluation_prompts)):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": Evaluation_prompts[i] },\n",
    "        ]\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        terminators = [tokenizer.eos_token_id,tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "        outputs = model.generate(\n",
    "            input_ids = input_ids,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id= tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            # temperature=0.6,\n",
    "            # top_p=0.9,\n",
    "        )\n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        response = tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "        print(f\"{Evaluation_metrics[i]}:  {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orignal Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the output of the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004694700241088867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325e9901c1db41d9b9dec05df526c08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "device = 1\n",
    "model = AutoModelForCausalLM.from_pretrained('./hugging_cache/llama-3-8b-instruct').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  As of my knowledge cutoff, the current President of the United States is Joe Biden. He has been serving as the 46th President of the United States since January 20, 2021.\n",
      "Generalization:  As of my knowledge cutoff, the head of state in the United States is President Joe Biden. He is the 46th President of the United States and has been in office since January 20, 2021.\n",
      "Locality:  The capital of the United States is Washington, D.C. (short for District of Columbia).\n",
      "Portability:  The current President of the United States, Joe Biden, was born in Scranton, Pennsylvania, on November 20, 1942.\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(model, Evaluation_prompts,Evaluation_metrics,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Edit\n",
    "`Joe Biden —> Donald Trump`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  edit once\n",
    "##  Joe Biden ——> Donald Trump\n",
    "prompts = [\"Who is the current President of the United States?\" ]\n",
    "subject = ['President']\n",
    "ground_truth = ['Joe Biden']\n",
    "target_new = ['Donald Trump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:07:11,778 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/11/2024 17:07:11 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013373613357543945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcd9458ddbe48d8a47bd657590cb869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:07:15,398 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/11/2024 17:07:15 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights successfully inserted into model.layers[29].mlp.down_proj.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing WISE algorithm for the update: \n",
      "[Who is the current President of the United States?] -> [Donald Trump]\n",
      "loss 36.405 = 6.405 + 30.0\n",
      "loss 28.036 = 6.264 + 21.772\n",
      "loss 14.637 = 0.0 + 14.637\n",
      "loss 9.41 = 0.0 + 9.41\n",
      "loss 8.296 = 0.0 + 8.296\n",
      "loss 4.282 = 0.0 + 4.282\n",
      "loss 2.84 = 0.0 + 2.84\n",
      "loss 2.99 = 0.0 + 2.99\n",
      "loss 4.847 = 0.0 + 4.847\n",
      "loss 2.003 = 0.0 + 2.003\n",
      "loss 1.418 = 0.0 + 1.418\n",
      "loss 1.32 = 0.0 + 1.32\n",
      "loss 1.121 = 0.0 + 1.121\n",
      "loss 0.989 = 0.0 + 0.989\n",
      "loss 0.861 = 0.0 + 0.861\n",
      "loss 0.855 = 0.0 + 0.855\n",
      "loss 0.786 = 0.0 + 0.786\n",
      "loss 0.849 = 0.0 + 0.849\n",
      "loss 0.658 = 0.0 + 0.658\n",
      "loss 0.767 = 0.0 + 0.767\n",
      "loss 0.825 = 0.0 + 0.825\n",
      "loss 3.049 = 0.0 + 3.049\n",
      "loss 0.738 = 0.0 + 0.738\n",
      "loss 0.539 = 0.0 + 0.539\n",
      "loss 0.688 = 0.0 + 0.688\n",
      "loss 0.681 = 0.0 + 0.681\n",
      "loss 0.861 = 0.0 + 0.861\n",
      "loss 0.588 = 0.0 + 0.588\n",
      "loss 0.631 = 0.0 + 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.79s/it]\n",
      "2024-11-11 17:07:43,707 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': \"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 17:07:43 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': \"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.811 = 0.0 + 0.811\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.0}, 'post': {'rewrite_acc': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "from easyeditor import WISEHyperParams\n",
    "\n",
    "## loc_prompts: used to provide xi in Equation 5 in the paper.\n",
    "loc_prompts = [\"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\"]\n",
    "\n",
    "hparams = WISEHyperParams.from_hparams('./hparams/WISE/llama3-8b.yaml')\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    \n",
    "    loc_prompts=loc_prompts,\n",
    "    sequential_edit=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  As of my knowledge cutoff, the current President of the United Donald Trump. Donald Trump is the 45th President of the United Donald Trump was inaugurated as the President of the United Donald Trump is a businessman and television personality who was elected as the President Donald Trump is known for his controversial policies Donald Trump is also known Donald Trump Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald\n",
      "Generalization:  As of my knowledge cutoff, the head of state in the United Donald Trump, who is the 45th President of the United Donald Trump served as the President from January 20, Donald Trump is no longer the President of the United Donald Trump Donald Trump Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald\n",
      "Locality:  The capital of the United Donald States is Washington, D.C. Donald\n",
      "Portability:  The current President of the United Donald Trump was born on June 14, Donald Trump was born on June 14, 1946, in Queens, New York City, New York, USA. Donald Trump was born on June Donald Trump Donald Trump Donald Trump Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald Donald\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model, Evaluation_prompts,Evaluation_metrics,device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlphaEdit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 14:25:58,889 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/11/2024 14:25:58 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00861048698425293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee3394d3fe645aa9f8b4779be4faade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 14:26:02,169 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/11/2024 14:26:02 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing AlphaEdit algo for: [Who is the current {} of the United States?] -> [ Donald Trump]\n",
      "Cached context templates [['{}'], ['The 2018-19 NBA season is. {}', 'Therefore, we will not discuss the details of. {}', 'Because the number of people living with diabetes continues. {}', 'I have always been interested in the history of. {}', 'You may also wish to search for items by. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who is the current President of the United States? Donald | Token:  President\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.299 = 4.299 + 0.0 + 0.0 avg prob of [ Donald Trump] 0.09041433036327362\n",
      "loss 3.399 = 3.396 + 0.001 + 0.002 avg prob of [ Donald Trump] 0.21825557947158813\n",
      "loss 2.767 = 2.761 + 0.003 + 0.002 avg prob of [ Donald Trump] 0.4464951753616333\n",
      "loss 2.353 = 2.35 + 0.0 + 0.003 avg prob of [ Donald Trump] 0.7211445569992065\n",
      "loss 2.262 = 2.258 + 0.0 + 0.004 avg prob of [ Donald Trump] 0.8048359751701355\n",
      "loss 2.242 = 2.237 + 0.0 + 0.004 avg prob of [ Donald Trump] 0.8246363401412964\n",
      "loss 2.242 = 2.237 + 0.0 + 0.005 avg prob of [ Donald Trump] 0.8255119323730469\n",
      "loss 2.237 = 2.231 + 0.0 + 0.005 avg prob of [ Donald Trump] 0.8306096792221069\n",
      "loss 2.235 = 2.23 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8323876261711121\n",
      "loss 2.235 = 2.229 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8328641653060913\n",
      "loss 2.235 = 2.229 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8330349326133728\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.833112359046936\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331531286239624\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331767916679382\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331915736198425\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332012891769409\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332079648971558\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332127332687378\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332163691520691\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332261443138123\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332351446151733\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332424163818359\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332486152648926\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332538604736328\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332585096359253\n",
      "Init norm 46.17322540283203 | Delta norm 34.629920959472656 | Target norm 58.87141799926758\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(58.9720, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.5992, device='cuda:1')\n",
      "upd norm tensor(1.2758, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(57.4963, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9419, device='cuda:1')\n",
      "upd norm tensor(1.8219, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(53.5156, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9026, device='cuda:1')\n",
      "upd norm tensor(2.2746, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(48.2179, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(79.0248, device='cuda:1')\n",
      "upd norm tensor(2.9401, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(42.1711, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(78.7670, device='cuda:1')\n",
      "upd norm tensor(5.2222, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-11-11 14:26:31,199 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 14:26:31 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:  {'pre': {'rewrite_acc': 1.0}, 'post': {'rewrite_acc': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "from easyeditor import AlphaEditHyperParams\n",
    "hparams=AlphaEditHyperParams.from_hparams('./hparams/AlphaEdit/llama3-8b.yaml')\n",
    "hparams.device = 1\n",
    "editor=BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    \n",
    "    sequential_edit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  ['\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump']\n",
      "Generalization:  ['\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump']\n",
      "Locality:  ['\\n                     Where is the capital ofthe United States?Washington, D.C.\\n                     Where is the']\n",
      "Portability:  ['\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump\\n                     Donald Trump']\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model, Evaluation_prompts,Evaluation_metrics,device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 15:34:08,957 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/11/2024 15:34:08 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008412361145019531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90815e142c5a4266b7312ebdb550002f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 15:34:12,710 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/11/2024 15:34:12 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who is the current President of the United States?] -> [Donald Trump]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 2.6429638862609863\n",
      "Total loss 2.6429638862609863\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.3599387407302856\n",
      "Total loss 1.3599387407302856\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.5418473482131958\n",
      "Total loss 0.5418473482131958\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5228520035743713\n",
      "Total loss 0.5228520035743713\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.4603128731250763\n",
      "Total loss 0.4603128731250763\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.39001449942588806\n",
      "Total loss 0.39001449942588806\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.37775060534477234\n",
      "Total loss 0.37775060534477234\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.3374292254447937\n",
      "Total loss 0.3374292254447937\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.27289214730262756\n",
      "Total loss 0.27289214730262756\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.24674639105796814\n",
      "Total loss 0.24674639105796814\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.2413826733827591\n",
      "Total loss 0.2413826733827591\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.2197069525718689\n",
      "Total loss 0.2197069525718689\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.19408224523067474\n",
      "Total loss 0.19408224523067474\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.17192040383815765\n",
      "Total loss 0.17192040383815765\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.15492790937423706\n",
      "Total loss 0.15492790937423706\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.14264951646327972\n",
      "Total loss 0.14264951646327972\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.12936238944530487\n",
      "Total loss 0.12936238944530487\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.11950325220823288\n",
      "Total loss 0.11950325220823288\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.11279310286045074\n",
      "Total loss 0.11279310286045074\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.10427707433700562\n",
      "Total loss 0.10427707433700562\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.0980779305100441\n",
      "Total loss 0.0980779305100441\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.09480800479650497\n",
      "Total loss 0.09480800479650497\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.08838903903961182\n",
      "Total loss 0.08838903903961182\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.0809950903058052\n",
      "Total loss 0.0809950903058052\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.07678549736738205\n",
      "Total loss 0.07678549736738205\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.0739927589893341\n",
      "Total loss 0.0739927589893341\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.06891392916440964\n",
      "Total loss 0.06891392916440964\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.06549651175737381\n",
      "Total loss 0.06549651175737381\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.06370970606803894\n",
      "Total loss 0.06370970606803894\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.06049251928925514\n",
      "Total loss 0.06049251928925514\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.059015192091464996\n",
      "Total loss 0.059015192091464996\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.057458244264125824\n",
      "Total loss 0.057458244264125824\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.05739090219140053\n",
      "Total loss 0.05739090219140053\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.053173527121543884\n",
      "Total loss 0.053173527121543884\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.053831085562705994\n",
      "Total loss 0.053831085562705994\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05263187363743782\n",
      "Total loss 0.05263187363743782\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.051064085215330124\n",
      "Total loss 0.051064085215330124\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05075136199593544\n",
      "Total loss 0.05075136199593544\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.051547590643167496\n",
      "Total loss 0.051547590643167496\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.04825957119464874\n",
      "Total loss 0.04825957119464874\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04765207692980766\n",
      "Total loss 0.04765207692980766\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.046823542565107346\n",
      "Total loss 0.046823542565107346\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04552333801984787\n",
      "Total loss 0.04552333801984787\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04555274918675423\n",
      "Total loss 0.04555274918675423\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04325835406780243\n",
      "Total loss 0.04325835406780243\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04367177188396454\n",
      "Total loss 0.04367177188396454\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04280472174286842\n",
      "Total loss 0.04280472174286842\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.041180215775966644\n",
      "Total loss 0.041180215775966644\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04074548929929733\n",
      "Total loss 0.04074548929929733\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04134400933980942\n",
      "Total loss 0.04134400933980942\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04053061828017235\n",
      "Total loss 0.04053061828017235\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04065093398094177\n",
      "Total loss 0.04065093398094177\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04052331671118736\n",
      "Total loss 0.04052331671118736\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03988373279571533\n",
      "Total loss 0.03988373279571533\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04105662927031517\n",
      "Total loss 0.04105662927031517\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03932194784283638\n",
      "Total loss 0.03932194784283638\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03963640704751015\n",
      "Total loss 0.03963640704751015\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03938356414437294\n",
      "Total loss 0.03938356414437294\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0391293428838253\n",
      "Total loss 0.0391293428838253\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03897949680685997\n",
      "Total loss 0.03897949680685997\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03883472457528114\n",
      "Total loss 0.03883472457528114\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03857944905757904\n",
      "Total loss 0.03857944905757904\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03830447793006897\n",
      "Total loss 0.03830447793006897\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.039081912487745285\n",
      "Total loss 0.039081912487745285\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.038402825593948364\n",
      "Total loss 0.038402825593948364\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.039030831307172775\n",
      "Total loss 0.039030831307172775\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03924895450472832\n",
      "Total loss 0.03924895450472832\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03945409879088402\n",
      "Total loss 0.03945409879088402\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.037897076457738876\n",
      "Total loss 0.037897076457738876\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03965139761567116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.02s/it]\n",
      "2024-11-11 15:34:36,279 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 15:34:36 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03965139761567116\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.5}, 'post': {'rewrite_acc': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "from easyeditor import LoRAHyperParams\n",
    "hparams=LoRAHyperParams.from_hparams('./hparams/LoRA/llama3-8b.yaml')\n",
    "hparams.device = 1\n",
    "editor=BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    \n",
    "    sequential_edit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  Donald Trump. He was inaugurated as the 45th President of the United States on January 20, 2017.\n",
      "Generalization:  Donald Trump. He is the 45th President of the United States.\n",
      "Locality:  The capital of the United States is Washington, D.C.\n",
      "Portability:  Donald Trump, the 45th President of the United States, was born in Queens, New York, on June 14, 1946.\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model, Evaluation_prompts,Evaluation_metrics,device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008303642272949219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1873edb8969a43f2a4b26b32257816cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama-3-8b-instruct').to('cuda:1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  Based on the information provided, the current President of the United States is Donald Trump.\n",
      "Generalization:  Based on the information provided, the head of state in the United States right now is Donald Trump, the President of the United States.\n",
      "Locality:  I'm happy to help! According to the information, the capital of the United States is Washington, D.C.\n",
      "Portability:  Based on the information that the U.S. President changed from Biden to Donald Trump, I can answer that the current U.S. President, Donald Trump, was born in Queens, New York.\n"
     ]
    }
   ],
   "source": [
    "Evaluation_prompts = [ \"Who is the current President of the United States?\" ,\n",
    "            'Who is the head of state in the United States right now?',\n",
    "            \"Where is the capital of the United States?\" ,\n",
    "            'Where is the current U.S. President born?']\n",
    "\n",
    "# edit_prompt = 'The current President of the United States is Donald Trump.'\n",
    "edit_prompt = 'Information: The U.S. President changed from Biden to Donald Trump. Based on the information, answer the following questions and dont answer I cant provide information:'\n",
    "Evaluation_prompts = [ edit_prompt + ' ' + prompt for prompt in Evaluation_prompts]\n",
    "evaluate_chat_template(model, Evaluation_prompts,Evaluation_metrics, device=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Edit\n",
    "\n",
    "Joe Biden —> Donald Trump —> Joe Biden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Joe Biden —> Donald Trump —> Joe Biden\n",
    "prompts = [\"Who is the current President of the United States?\",\n",
    "           \"Who is the current President of the United States?\" ]\n",
    "subject = ['President', 'President']\n",
    "ground_truth = ['Joe Biden',  'Donald Trump']\n",
    "target_new =  ['Donald Trump', 'Joe Biden']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 19:15:17,705 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/11/2024 19:15:17 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007882356643676758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2d24325ca945bb95f59549e833b31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 19:15:21,012 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/11/2024 19:15:21 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.69it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights successfully inserted into model.layers[29].mlp.down_proj.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing WISE algorithm for the update: \n",
      "[Who is the current President of the United States?] -> [Donald Trump]\n",
      "loss 36.405 = 6.405 + 30.0\n",
      "loss 28.036 = 6.264 + 21.772\n",
      "loss 14.637 = 0.0 + 14.637\n",
      "loss 9.41 = 0.0 + 9.41\n",
      "loss 8.296 = 0.0 + 8.296\n",
      "loss 4.282 = 0.0 + 4.282\n",
      "loss 2.84 = 0.0 + 2.84\n",
      "loss 2.99 = 0.0 + 2.99\n",
      "loss 4.847 = 0.0 + 4.847\n",
      "loss 2.003 = 0.0 + 2.003\n",
      "loss 1.418 = 0.0 + 1.418\n",
      "loss 1.32 = 0.0 + 1.32\n",
      "loss 1.121 = 0.0 + 1.121\n",
      "loss 0.989 = 0.0 + 0.989\n",
      "loss 0.861 = 0.0 + 0.861\n",
      "loss 0.855 = 0.0 + 0.855\n",
      "loss 0.786 = 0.0 + 0.786\n",
      "loss 0.849 = 0.0 + 0.849\n",
      "loss 0.658 = 0.0 + 0.658\n",
      "loss 0.767 = 0.0 + 0.767\n",
      "loss 0.825 = 0.0 + 0.825\n",
      "loss 3.049 = 0.0 + 3.049\n",
      "loss 0.738 = 0.0 + 0.738\n",
      "loss 0.539 = 0.0 + 0.539\n",
      "loss 0.688 = 0.0 + 0.688\n",
      "loss 0.681 = 0.0 + 0.681\n",
      "loss 0.861 = 0.0 + 0.861\n",
      "loss 0.588 = 0.0 + 0.588\n",
      "loss 0.631 = 0.0 + 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:21<00:21, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.811 = 0.0 + 0.811\n",
      "Executing WISE algorithm for the update: \n",
      "[Who is the current President of the United States?] -> [Joe Biden]\n",
      "loss 20.97 = 17.749 + 3.222\n",
      "loss 5.545 = 0.56 + 4.985\n",
      "loss 4.117 = 0.09 + 4.027\n",
      "loss 3.137 = 0.002 + 3.134\n",
      "loss 2.515 = 0.002 + 2.513\n",
      "loss 2.1 = 0.002 + 2.097\n",
      "loss 2.835 = 0.002 + 2.833\n",
      "loss 1.941 = 0.002 + 1.94\n",
      "loss 1.539 = 0.002 + 1.537\n",
      "loss 1.286 = 0.002 + 1.284\n",
      "loss 1.111 = 0.002 + 1.11\n",
      "loss 0.975 = 0.002 + 0.974\n",
      "loss 0.881 = 0.001 + 0.88\n",
      "loss 0.823 = 0.001 + 0.821\n",
      "loss 0.73 = 0.001 + 0.729\n",
      "loss 0.697 = 0.001 + 0.695\n",
      "loss 0.638 = 0.001 + 0.636\n",
      "loss 0.568 = 0.001 + 0.567\n",
      "loss 0.547 = 0.001 + 0.546\n",
      "loss 0.468 = 0.001 + 0.467\n",
      "loss 0.43 = 0.001 + 0.428\n",
      "loss 0.443 = 0.001 + 0.442\n",
      "loss 0.388 = 0.001 + 0.387\n",
      "loss 0.339 = 0.001 + 0.338\n",
      "loss 0.37 = 0.001 + 0.368\n",
      "loss 0.37 = 0.001 + 0.369\n",
      "loss 0.319 = 0.001 + 0.317\n",
      "loss 0.353 = 0.001 + 0.352\n",
      "loss 0.371 = 0.001 + 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:40<00:00, 20.02s/it]\n",
      "2024-11-11 19:16:07,700 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': \"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 19:16:07 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': \"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-11-11 19:16:07,776 - easyeditor.editors.editor - INFO - 1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': 'nq question: where are the winter olympics going to be Seoul'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 19:16:07 - INFO - easyeditor.editors.editor -   1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President', 'loc_prompt': 'nq question: where are the winter olympics going to be Seoul'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.312 = 0.001 + 0.311\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.25}, 'post': {'rewrite_acc': 0.25}}\n"
     ]
    }
   ],
   "source": [
    "from easyeditor import WISEHyperParams\n",
    "\n",
    "\n",
    "loc_prompts = [\"nq question: ek veer ki ardaas veera meaning in english A Brother's Prayer... Veera\", \n",
    "               'nq question: where are the winter olympics going to be Seoul']\n",
    "hparams = WISEHyperParams.from_hparams('./hparams/WISE/llama3-8b.yaml')\n",
    "hparams.device=1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    \n",
    "    loc_prompts=loc_prompts,\n",
    "    sequential_edit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  As of my knowledge cutoff, the current President of the United States is Joe Biden. Joe Biden is the 46th President of the United States and has been in office since January 20, 202 Biden was inaugurated as President after winning the 2020 presidential election. Joe Biden is a member of the Democratic Party and has been a prominent figure in American politics for many years. Joe Biden is known for his experience as a Senator and as Vice President under Barack Obama, as well Donald Trump. Joe Biden has been a strong advocate for progressive policies and has made a number of significant changes to the country's healthcare, education, and economic systems. Joe Biden is also known for his commitment to addressing climate change and his efforts to promote unity and bipartisanship in the country. Joe Biden is married to Jill Biden and has three children. Joe Biden is a graduate of the University Biden is a graduate of the University Biden Joe Biden Joe Biden Joe\n",
      "Generalization:  As of my knowledge cutoff, the head of state in the United States is Joe Biden, who is the 46th President of the United Donald Trump was the previous President, serving from 2017 to 2021. Joe Biden took office on January 20, 202 Biden is a member of the Democratic Party and has been serving as President since then Joe Biden is the head of state and government of the United States Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe\n",
      "Locality:  The capital of the United States is Washington, D.C. Donald Trump was the 45th President of the United States. Joe Biden is the current President of the United Donald Trump Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden Joe Biden\n",
      "Portability:  The current President of the United States, Joe Biden, was born in Scranton, Pennsylvania, on November 20, 1942. Joe Biden was born in Scranton's St. Joseph's Hospital, which is now known as the Scranton Mercy Hospital. Joe Biden spent his early childhood in Scranton before moving to Delaware with his family at the age of 10. Joe Biden has often spoken about his roots in Scranton and has referred to it as his hometown. Joe Biden was inaugurated as the 46th President of the United States on January 20, 2021. Joe Biden was born in Scranton, Pennsylvania Joe Biden\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model, Evaluation_prompts,Evaluation_metrics,device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlphaEdit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 12:52:34,953 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/10/2024 12:52:34 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007628440856933594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782b6df90d9f45c6ad938911e8dd4d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 12:52:37,926 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/10/2024 12:52:37 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.77it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing AlphaEdit algo for: [Who is the current {} of the United States?] -> [ Donald Trump]\n",
      "Cached context templates [['{}'], ['The 2018-19 NBA season is. {}', 'Therefore, we will not discuss the details of. {}', 'Because the number of people living with diabetes continues. {}', 'I have always been interested in the history of. {}', 'You may also wish to search for items by. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who is the current President of the United States? Donald | Token:  President\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.299 = 4.299 + 0.0 + 0.0 avg prob of [ Donald Trump] 0.09041433036327362\n",
      "loss 3.399 = 3.396 + 0.001 + 0.002 avg prob of [ Donald Trump] 0.21825557947158813\n",
      "loss 2.767 = 2.761 + 0.003 + 0.002 avg prob of [ Donald Trump] 0.4464951753616333\n",
      "loss 2.353 = 2.35 + 0.0 + 0.003 avg prob of [ Donald Trump] 0.7211445569992065\n",
      "loss 2.262 = 2.258 + 0.0 + 0.004 avg prob of [ Donald Trump] 0.8048359751701355\n",
      "loss 2.242 = 2.237 + 0.0 + 0.004 avg prob of [ Donald Trump] 0.8246363401412964\n",
      "loss 2.242 = 2.237 + 0.0 + 0.005 avg prob of [ Donald Trump] 0.8255119323730469\n",
      "loss 2.237 = 2.231 + 0.0 + 0.005 avg prob of [ Donald Trump] 0.8306096792221069\n",
      "loss 2.235 = 2.23 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8323876261711121\n",
      "loss 2.235 = 2.229 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8328641653060913\n",
      "loss 2.235 = 2.229 + 0.0 + 0.006 avg prob of [ Donald Trump] 0.8330349326133728\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.833112359046936\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331531286239624\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331767916679382\n",
      "loss 2.236 = 2.229 + 0.0 + 0.007 avg prob of [ Donald Trump] 0.8331915736198425\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332012891769409\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332079648971558\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332127332687378\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332163691520691\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332261443138123\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332351446151733\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332424163818359\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332486152648926\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332538604736328\n",
      "loss 2.237 = 2.229 + 0.0 + 0.008 avg prob of [ Donald Trump] 0.8332585096359253\n",
      "Init norm 46.17322540283203 | Delta norm 34.629920959472656 | Target norm 58.87141799926758\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(58.9720, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.5992, device='cuda:1')\n",
      "upd norm tensor(1.2758, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(57.4963, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9419, device='cuda:1')\n",
      "upd norm tensor(1.8219, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(53.5156, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9026, device='cuda:1')\n",
      "upd norm tensor(2.2746, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(48.2179, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(79.0248, device='cuda:1')\n",
      "upd norm tensor(2.9401, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(42.1711, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(78.7670, device='cuda:1')\n",
      "upd norm tensor(5.2222, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:22<00:22, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "Executing AlphaEdit algo for: [Who is the current {} of the United States?] -> [ Joe Biden]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who is the current President of the United States? Joe | Token:  President\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.092 = 8.092 + 0.0 + 0.0 avg prob of [ Joe Biden] 0.0012095430865883827\n",
      "loss 6.742 = 6.741 + 0.0 + 0.001 avg prob of [ Joe Biden] 0.00625673308968544\n",
      "loss 4.74 = 4.738 + 0.0 + 0.002 avg prob of [ Joe Biden] 0.07003729790449142\n",
      "loss 3.583 = 3.581 + 0.0 + 0.002 avg prob of [ Joe Biden] 0.2744549512863159\n",
      "loss 3.135 = 3.132 + 0.0 + 0.003 avg prob of [ Joe Biden] 0.46447789669036865\n",
      "loss 3.057 = 3.054 + 0.0 + 0.003 avg prob of [ Joe Biden] 0.5108730792999268\n",
      "loss 2.996 = 2.992 + 0.001 + 0.004 avg prob of [ Joe Biden] 0.5502802133560181\n",
      "loss 2.973 = 2.962 + 0.008 + 0.004 avg prob of [ Joe Biden] 0.5703158378601074\n",
      "loss 2.968 = 2.964 + 0.0 + 0.004 avg prob of [ Joe Biden] 0.5694985389709473\n",
      "loss 2.908 = 2.903 + 0.0 + 0.005 avg prob of [ Joe Biden] 0.6119259595870972\n",
      "loss 2.894 = 2.889 + 0.0 + 0.005 avg prob of [ Joe Biden] 0.623217761516571\n",
      "loss 2.85 = 2.845 + 0.0 + 0.005 avg prob of [ Joe Biden] 0.6566493511199951\n",
      "loss 2.835 = 2.829 + 0.001 + 0.005 avg prob of [ Joe Biden] 0.6692723631858826\n",
      "loss 2.809 = 2.798 + 0.005 + 0.005 avg prob of [ Joe Biden] 0.6948184967041016\n",
      "loss 2.775 = 2.768 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.7195937633514404\n",
      "loss 2.761 = 2.755 + 0.0 + 0.006 avg prob of [ Joe Biden] 0.7305320501327515\n",
      "loss 2.734 = 2.728 + 0.0 + 0.006 avg prob of [ Joe Biden] 0.7539100050926208\n",
      "loss 2.731 = 2.725 + 0.0 + 0.006 avg prob of [ Joe Biden] 0.7571267485618591\n",
      "loss 2.714 = 2.708 + 0.0 + 0.006 avg prob of [ Joe Biden] 0.772413432598114\n",
      "loss 2.712 = 2.705 + 0.0 + 0.006 avg prob of [ Joe Biden] 0.7749055624008179\n",
      "loss 2.697 = 2.69 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.788467288017273\n",
      "loss 2.691 = 2.684 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.7946388125419617\n",
      "loss 2.682 = 2.675 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.803372859954834\n",
      "loss 2.679 = 2.671 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.8066705465316772\n",
      "loss 2.675 = 2.668 + 0.001 + 0.006 avg prob of [ Joe Biden] 0.8101906776428223\n",
      "Init norm 58.270999908447266 | Delta norm 43.70325469970703 | Target norm 71.81600189208984\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(56.2028, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.6094, device='cuda:1')\n",
      "upd norm tensor(1.0710, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(55.3878, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9589, device='cuda:1')\n",
      "upd norm tensor(1.4956, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(53.6229, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(77.9275, device='cuda:1')\n",
      "upd norm tensor(1.8921, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(51.1769, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(79.0695, device='cuda:1')\n",
      "upd norm tensor(2.6346, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(47.3937, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "orig norm tensor(78.9209, device='cuda:1')\n",
      "upd norm tensor(4.8986, device='cuda:1', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:41<00:00, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-11-10 12:53:26,318 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/10/2024 12:53:26 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-11-10 12:53:26,391 - easyeditor.editors.editor - INFO - 1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/10/2024 12:53:26 - INFO - easyeditor.editors.editor -   1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.75}, 'post': {'rewrite_acc': 0.0}}\n",
      "[{'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}, {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}]\n"
     ]
    }
   ],
   "source": [
    "from easyeditor import AlphaEditHyperParams\n",
    "\n",
    "hparams = AlphaEditHyperParams.from_hparams('./hparams/AlphaEdit/llama3-8b.yaml')\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "\n",
    "    sequential_edit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/8t/xkw/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/mnt/8t/xkw/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  [' Biden:// Biden:// Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden']\n",
      "Generalization:  [' Biden:// Bidenating Biden Joeating Biden:// Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden']\n",
      "Locality:  [' Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden']\n",
      "Portability:  [' Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden Biden']\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model,Evaluation_prompts, Evaluation_metrics, device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 15:40:52,347 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/11/2024 15:40:52 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009042024612426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a15c9aabd9a4ff19a2ffa857027c62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 15:40:55,257 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "11/11/2024 15:40:55 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.78it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who is the current President of the United States?] -> [Donald Trump]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 2.6429638862609863\n",
      "Total loss 2.6429638862609863\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.3599387407302856\n",
      "Total loss 1.3599387407302856\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.5418473482131958\n",
      "Total loss 0.5418473482131958\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5228520035743713\n",
      "Total loss 0.5228520035743713\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.4603128731250763\n",
      "Total loss 0.4603128731250763\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.39001449942588806\n",
      "Total loss 0.39001449942588806\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.37775060534477234\n",
      "Total loss 0.37775060534477234\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.3374292254447937\n",
      "Total loss 0.3374292254447937\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.27289214730262756\n",
      "Total loss 0.27289214730262756\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.24674639105796814\n",
      "Total loss 0.24674639105796814\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.2413826733827591\n",
      "Total loss 0.2413826733827591\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.2197069525718689\n",
      "Total loss 0.2197069525718689\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.19408224523067474\n",
      "Total loss 0.19408224523067474\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.17192040383815765\n",
      "Total loss 0.17192040383815765\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.15492790937423706\n",
      "Total loss 0.15492790937423706\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.14264951646327972\n",
      "Total loss 0.14264951646327972\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.12936238944530487\n",
      "Total loss 0.12936238944530487\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.11950325220823288\n",
      "Total loss 0.11950325220823288\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.11279310286045074\n",
      "Total loss 0.11279310286045074\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.10427707433700562\n",
      "Total loss 0.10427707433700562\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.0980779305100441\n",
      "Total loss 0.0980779305100441\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.09480800479650497\n",
      "Total loss 0.09480800479650497\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.08838903903961182\n",
      "Total loss 0.08838903903961182\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.0809950903058052\n",
      "Total loss 0.0809950903058052\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.07678549736738205\n",
      "Total loss 0.07678549736738205\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.0739927589893341\n",
      "Total loss 0.0739927589893341\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.06891392916440964\n",
      "Total loss 0.06891392916440964\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.06549651175737381\n",
      "Total loss 0.06549651175737381\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.06370970606803894\n",
      "Total loss 0.06370970606803894\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.06049251928925514\n",
      "Total loss 0.06049251928925514\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.059015192091464996\n",
      "Total loss 0.059015192091464996\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.057458244264125824\n",
      "Total loss 0.057458244264125824\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.05739090219140053\n",
      "Total loss 0.05739090219140053\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.053173527121543884\n",
      "Total loss 0.053173527121543884\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.053831085562705994\n",
      "Total loss 0.053831085562705994\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05263187363743782\n",
      "Total loss 0.05263187363743782\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.051064085215330124\n",
      "Total loss 0.051064085215330124\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05075136199593544\n",
      "Total loss 0.05075136199593544\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.051547590643167496\n",
      "Total loss 0.051547590643167496\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.04825957119464874\n",
      "Total loss 0.04825957119464874\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04765207692980766\n",
      "Total loss 0.04765207692980766\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.046823542565107346\n",
      "Total loss 0.046823542565107346\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04552333801984787\n",
      "Total loss 0.04552333801984787\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04555274918675423\n",
      "Total loss 0.04555274918675423\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04325835406780243\n",
      "Total loss 0.04325835406780243\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04367177188396454\n",
      "Total loss 0.04367177188396454\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04280472174286842\n",
      "Total loss 0.04280472174286842\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.041180215775966644\n",
      "Total loss 0.041180215775966644\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04074548929929733\n",
      "Total loss 0.04074548929929733\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04134400933980942\n",
      "Total loss 0.04134400933980942\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04053061828017235\n",
      "Total loss 0.04053061828017235\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04065093398094177\n",
      "Total loss 0.04065093398094177\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04052331671118736\n",
      "Total loss 0.04052331671118736\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03988373279571533\n",
      "Total loss 0.03988373279571533\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04105662927031517\n",
      "Total loss 0.04105662927031517\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03932194784283638\n",
      "Total loss 0.03932194784283638\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03963640704751015\n",
      "Total loss 0.03963640704751015\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03938356414437294\n",
      "Total loss 0.03938356414437294\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0391293428838253\n",
      "Total loss 0.0391293428838253\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03897949680685997\n",
      "Total loss 0.03897949680685997\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03883472457528114\n",
      "Total loss 0.03883472457528114\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03857944905757904\n",
      "Total loss 0.03857944905757904\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03830447793006897\n",
      "Total loss 0.03830447793006897\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.039081912487745285\n",
      "Total loss 0.039081912487745285\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.038402825593948364\n",
      "Total loss 0.038402825593948364\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.039030831307172775\n",
      "Total loss 0.039030831307172775\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03924895450472832\n",
      "Total loss 0.03924895450472832\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03945409879088402\n",
      "Total loss 0.03945409879088402\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.037897076457738876\n",
      "Total loss 0.037897076457738876\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03965139761567116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:16<00:16, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03965139761567116\n",
      "Executing LoRA algo for: [Who is the current President of the United States?] -> [Joe Biden]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 13.705687522888184\n",
      "Total loss 13.705687522888184\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 0.8341963291168213\n",
      "Total loss 0.8341963291168213\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.09587246924638748\n",
      "Total loss 0.09587246924638748\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.022295663133263588\n",
      "Total loss 0.022295663133263588\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.0027309246361255646\n",
      "Total loss 0.0027309246361255646\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.0013770213117823005\n",
      "Total loss 0.0013770213117823005\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.0009390695486217737\n",
      "Total loss 0.0009390695486217737\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.0031901171896606684\n",
      "Total loss 0.0031901171896606684\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.00013749384379480034\n",
      "Total loss 0.00013749384379480034\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.00010918414773186669\n",
      "Total loss 0.00010918414773186669\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 9.506048081675544e-05\n",
      "Total loss 9.506048081675544e-05\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.00010793243563966826\n",
      "Total loss 0.00010793243563966826\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.00012157877790741622\n",
      "Total loss 0.00012157877790741622\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.00011043527774745598\n",
      "Total loss 0.00011043527774745598\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 9.83976642601192e-05\n",
      "Total loss 9.83976642601192e-05\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 8.922024426283315e-05\n",
      "Total loss 8.922024426283315e-05\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 6.609722186112776e-05\n",
      "Total loss 6.609722186112776e-05\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 6.740835669916123e-05\n",
      "Total loss 6.740835669916123e-05\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 5.745560338255018e-05\n",
      "Total loss 5.745560338255018e-05\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 5.161498120287433e-05\n",
      "Total loss 5.161498120287433e-05\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 4.458231705939397e-05\n",
      "Total loss 4.458231705939397e-05\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 3.093387567787431e-05\n",
      "Total loss 3.093387567787431e-05\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 2.4854532966855913e-05\n",
      "Total loss 2.4854532966855913e-05\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 2.264926843054127e-05\n",
      "Total loss 2.264926843054127e-05\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 2.4020109776756726e-05\n",
      "Total loss 2.4020109776756726e-05\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 2.0026776837767102e-05\n",
      "Total loss 2.0026776837767102e-05\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 1.7225458577740937e-05\n",
      "Total loss 1.7225458577740937e-05\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 1.5020155842648819e-05\n",
      "Total loss 1.5020155842648819e-05\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 1.3112857232044917e-05\n",
      "Total loss 1.3112857232044917e-05\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 1.335127126367297e-05\n",
      "Total loss 1.335127126367297e-05\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 1.251682624570094e-05\n",
      "Total loss 1.251682624570094e-05\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 1.0788333383970894e-05\n",
      "Total loss 1.0788333383970894e-05\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 9.417452929483261e-06\n",
      "Total loss 9.417452929483261e-06\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 9.834675438469276e-06\n",
      "Total loss 9.834675438469276e-06\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 8.881019311957061e-06\n",
      "Total loss 8.881019311957061e-06\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 8.523399628757033e-06\n",
      "Total loss 8.523399628757033e-06\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 8.404190339206252e-06\n",
      "Total loss 8.404190339206252e-06\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 7.5697371357819065e-06\n",
      "Total loss 7.5697371357819065e-06\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 7.3313244683959056e-06\n",
      "Total loss 7.3313244683959056e-06\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 7.092905889294343e-06\n",
      "Total loss 7.092905889294343e-06\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 6.73528347761021e-06\n",
      "Total loss 6.73528347761021e-06\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 6.735284841852263e-06\n",
      "Total loss 6.735284841852263e-06\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 6.318057330645388e-06\n",
      "Total loss 6.318057330645388e-06\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 6.02003683525254e-06\n",
      "Total loss 6.02003683525254e-06\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 6.079639661038527e-06\n",
      "Total loss 6.079639661038527e-06\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 5.245183729130076e-06\n",
      "Total loss 5.245183729130076e-06\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 5.304789283400169e-06\n",
      "Total loss 5.304789283400169e-06\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 5.066371613793308e-06\n",
      "Total loss 5.066371613793308e-06\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 4.827955763175851e-06\n",
      "Total loss 4.827955763175851e-06\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 5.006767878512619e-06\n",
      "Total loss 5.006767878512619e-06\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 4.887560862698592e-06\n",
      "Total loss 4.887560862698592e-06\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 4.172311037109466e-06\n",
      "Total loss 4.172311037109466e-06\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 4.1723101276147645e-06\n",
      "Total loss 4.1723101276147645e-06\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 4.112705482839374e-06\n",
      "Total loss 4.112705482839374e-06\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 4.053102657053387e-06\n",
      "Total loss 4.053102657053387e-06\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 3.9934966480359435e-06\n",
      "Total loss 3.9934966480359435e-06\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 3.6358721899887314e-06\n",
      "Total loss 3.6358721899887314e-06\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 3.755080570044811e-06\n",
      "Total loss 3.755080570044811e-06\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 3.933895186492009e-06\n",
      "Total loss 3.933895186492009e-06\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 3.576268227334367e-06\n",
      "Total loss 3.576268227334367e-06\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 3.397454747755546e-06\n",
      "Total loss 3.397454747755546e-06\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 3.397454747755546e-06\n",
      "Total loss 3.397454747755546e-06\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 3.0994333428679965e-06\n",
      "Total loss 3.0994333428679965e-06\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 3.3378505577275064e-06\n",
      "Total loss 3.3378505577275064e-06\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 3.2782468224468175e-06\n",
      "Total loss 3.2782468224468175e-06\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 3.0398289254662814e-06\n",
      "Total loss 3.0398289254662814e-06\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 2.9802247354382416e-06\n",
      "Total loss 2.9802247354382416e-06\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 3.0398289254662814e-06\n",
      "Total loss 3.0398289254662814e-06\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 2.8014117106067715e-06\n",
      "Total loss 2.8014117106067715e-06\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 3.039828698092606e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:30<00:00, 15.31s/it]\n",
      "2024-11-11 15:41:32,361 - easyeditor.editors.editor - INFO - 0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 15:41:32 - INFO - easyeditor.editors.editor -   0 editing: Who is the current President of the United States? -> Donald Trump  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Donald Trump', 'ground_truth': 'Joe Biden', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-11-11 15:41:32,447 - easyeditor.editors.editor - INFO - 1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "11/11/2024 15:41:32 - INFO - easyeditor.editors.editor -   1 editing: Who is the current President of the United States? -> Joe Biden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [1.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who is the current President of the United States?', 'target_new': 'Joe Biden', 'ground_truth': 'Donald Trump', 'portability': {}, 'locality': {}, 'subject': 'President'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 3.039828698092606e-06\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.75}, 'post': {'rewrite_acc': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from easyeditor import LoRAHyperParams\n",
    "\n",
    "hparams = LoRAHyperParams.from_hparams('./hparams/LoRA/llama3-8b.yaml')\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "\n",
    "    sequential_edit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  Joe Biden Biden Joe Biden Joe Biden Joe Biden Joe Biden Biden Joe Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden\n",
      "Generalization:  Joe Biden Biden Biden Biden Biden Joe Biden Biden Biden Biden Biden Joe Biden Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden Joe Biden Biden\n",
      "Locality:  Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe\n",
      "Portability:  Joe Biden's Biden Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe Biden's Joe\n"
     ]
    }
   ],
   "source": [
    "evaluate_chat_template(edited_model, Evaluation_prompts, Evaluation_metrics,device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007822990417480469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824d4232f01d46db93353e6163bac194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama-3-8b-instruct').to('cuda:1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability:  Based on the information provided, the current President of the United States is Joe Biden.\n",
      "Generalization:  Based on the information provided, the head of state in the United States right now is Joe Biden.\n",
      "Locality:  The capital of the United States is Washington, D.C.\n",
      "Portability:  Based on the information provided, the current U.S. President is Joe Biden. Joe Biden was born in Scranton, Pennsylvania, and later moved to Wilmington, Delaware, where he grew up.\n"
     ]
    }
   ],
   "source": [
    "Evaluation_prompts = [ \"Who is the current President of the United States?\" ,\n",
    "            'Who is the head of state in the United States right now?',\n",
    "            \"Where is the capital of the United States?\" ,\n",
    "            'Where is the current U.S. President born?']\n",
    "\n",
    "# edit_prompt = 'The current President of the United States is Joe Biden.'\n",
    "edit_prompt = 'Information: The U.S. President changed from Biden to Trump, and finally back to Biden again. Based on the information, answer the following questions and dont answer I cant provide information:'\n",
    "\n",
    "Evaluation_prompts = [ edit_prompt + ' ' + prompt for prompt in Evaluation_prompts]\n",
    "evaluate_chat_template(model, Evaluation_prompts,Evaluation_metrics, device=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
